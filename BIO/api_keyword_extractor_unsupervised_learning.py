from flask import Flask, request, jsonify
from keybert import KeyBERT
from transformers import AutoTokenizer
import torch

# KeyBERTì— ì‚¬ìš©í•  í•œêµ­ì–´ ëª¨ë¸ ë¡œë“œ
model_name = "allenai/scibert_scivocab_uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
kw_model = KeyBERT(model_name)

# ìµœëŒ€ í† í° ê¸¸ì´ ì„¤ì • (BERT ê³„ì—´ì€ 512)
MAX_TOKENS = 128

app = Flask(__name__)

def split_doc_by_tokens(doc, max_tokens=MAX_TOKENS):
    tokens = tokenizer.tokenize(doc)
    chunks = []

    # í† í°ì„ max_tokens ê°œì”© ë‚˜ëˆ”
    for i in range(0, len(tokens), max_tokens):
        chunk_tokens = tokens[i:i + max_tokens]
        chunk_text = tokenizer.convert_tokens_to_string(chunk_tokens)
        chunks.append(chunk_text.strip())

    return chunks

@app.route("/extract_keywords", methods=["POST"])
def extract_keywords():
    data = request.get_json()

    if not data or 'doc' not in data:
        return jsonify({"error": "Missing 'doc' in request body"}), 400

    doc = data['doc']
    chunks = split_doc_by_tokens(doc)

    all_keywords = []

    for chunk in chunks:
        # print("chunk: ", chunk)
        keywords_with_scores = kw_model.extract_keywords(
            chunk,
            # keyphrase_ngram_range=(1, 1),   # 1~3ë‹¨ì–´ í‚¤ì›Œë“œ í›„ë³´
            stop_words=None,  # ë¶ˆìš©ì–´ ì œê±° ì•ˆ í•¨ â†’ ë” ë§ì€ í‚¤ì›Œë“œ í›„ë³´ ìœ ì§€
            use_maxsum=False,  # ë‹¤ì–‘ì„± ì œì•½ ì—†ìŒ (ë§ì´ ë½‘ëŠ” ë° ìœ ë¦¬)
            use_mmr=False,  # ìœ ì‚¬ë„ ë‹¤ì–‘ì„± ì œì•½ ì—†ìŒ
            top_n=32  # ìµœëŒ€í•œ ë§ì´ ë½‘ëŠ”ë‹¤
        )
        filtered = [
            {"keyword": kw, "score": float(score)}
            for kw, score in keywords_with_scores if score >= 0.5
        ]

        all_keywords.extend(filtered)

    # ì¤‘ë³µ í‚¤ì›Œë“œ ì œê±° (ì„ íƒ)
    seen = set()
    unique_keywords = []
    for kw in all_keywords:
        if kw['keyword'] not in seen:
            unique_keywords.append(kw)
            seen.add(kw['keyword'])

    # ğŸ”½ scoreë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    filtered_sorted = sorted(unique_keywords, key=lambda x: x["score"], reverse=True)

    # ğŸ”½ keyword ê°’ë§Œ ì¶”ì¶œ
    keywords_only = [item["keyword"] for item in filtered_sorted]

    return jsonify({"keywords": keywords_only})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001, debug=True)